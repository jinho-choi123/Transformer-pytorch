{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826c28a6-3b2c-41ec-9615-c83c0bf22745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run ../config/config.ipynb\n",
    "%run ./Transformer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad4a287-4556-4de2-820f-3ac7981fa2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b843f057-7682-45b0-b176-7fc6d844d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model in the models/ directory \n",
    "model_name = \"model_20241119_142930_2\"\n",
    "model_path = model_dir / model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ee2d7d-aced-436a-970b-78752d646def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (emb): TransformerEmbedding(\n",
       "      (token_emb): TokenEmbeddings(65001, 400, padding_idx=1)\n",
       "      (position_emb): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x EncoderLayer(\n",
       "        (attention): MultiHeadAttentionBlock(\n",
       "          (attention): AttentionBlock(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (Wq): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wk): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wv): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wconcat): Linear(in_features=400, out_features=400, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): FeedForwardBlock(\n",
       "          (linear1): Linear(in_features=400, out_features=1200, bias=True)\n",
       "          (linear2): Linear(in_features=1200, out_features=400, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (emb): TransformerEmbedding(\n",
       "      (token_emb): TokenEmbeddings(65001, 400, padding_idx=1)\n",
       "      (position_emb): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x DecoderLayer(\n",
       "        (self_attention): MultiHeadAttentionBlock(\n",
       "          (attention): AttentionBlock(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (Wq): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wk): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wv): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wconcat): Linear(in_features=400, out_features=400, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (enc_dec_attention): MultiHeadAttentionBlock(\n",
       "          (attention): AttentionBlock(\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (Wq): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wk): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wv): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (Wconcat): Linear(in_features=400, out_features=400, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): FeedForwardBlock(\n",
       "          (linear1): Linear(in_features=400, out_features=1200, bias=True)\n",
       "          (linear2): Linear(in_features=1200, out_features=400, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm3): LayerNorm()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=400, out_features=65001, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model \n",
    "model = Transformer(\n",
    "    src_pad_token=src_pad_token, \n",
    "    trg_pad_token=trg_pad_token, \n",
    "    enc_voc_size=enc_voc_size, \n",
    "    dec_voc_size=dec_voc_size, \n",
    "    n_head=n_head, \n",
    "    max_len=max_len, \n",
    "    d_model=d_model, \n",
    "    ffn_hidden=ffn_hidden, \n",
    "    n_layers=n_layers, \n",
    "    drop_prob=drop_prob, \n",
    "    device=device).to(device)\n",
    "\n",
    "# load weights from the saved model \n",
    "model.load_state_dict(torch.load(model_path, weights_only=True, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64269808-0be2-45f5-b5bf-d1f23160fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function \n",
    "def tensor2tokenid(tensor): \n",
    "    # convert tensor to tokenid \n",
    "    # by picking index that has max value \n",
    "    # use argmax \n",
    "    token_id = torch.argmax(tensor, dim=-1)\n",
    "    return token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66ec331b-a954-44e0-bebe-783f3ea05ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a inference function that takes korean sentence, and outputs english sentence.\n",
    "# for generating english sentence, we are going to limit the output token length by limit_token_length\n",
    "def inference(kr_sentence): \n",
    "    with torch.no_grad():\n",
    "        limit_token_length = max_len - 1\n",
    "        # since we are going to generete English sentence in autoregressive manner, \n",
    "        # we have to define the starting point.\n",
    "        # make a max_len length tensor that first element is trg_sos_token, \n",
    "        # and others filled with trg_pad_token\n",
    "        # reshape to set batch_size as 1 \n",
    "        trg_token_ids = en_tokenizer.encode('</s>', return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "        # trg_token_ids[0] = trg_eos_token\n",
    "        trg_token_ids = trg_token_ids.reshape((1, -1)).to(device)\n",
    "        # print(trg_token_ids.shape)\n",
    "        # print(trg_token_ids.type())\n",
    "        \n",
    "        # tokenize src sentence \n",
    "        src_token_ids = kr_tokenizer(kr_sentence, add_special_tokens=True, padding=\"max_length\", max_length=max_len, truncation=True).input_ids\n",
    "        src_token_ids = torch.tensor(src_token_ids).reshape((1, -1)).to(device)\n",
    "        # print(src_token_ids.shape)\n",
    "        # print(src_token_ids.type())\n",
    "        \n",
    "        # make src_mask and trg_mask\n",
    "        src_mask = model.make_src_mask(src_token_ids)\n",
    "        # print(src_mask)\n",
    "    \n",
    "        # get enc_src using model.encoder \n",
    "        # we can use whole transformer iteratively, but \n",
    "        # since we are going to reuse enc_src, \n",
    "        # we are going to cache it, and reuse it\n",
    "        enc_src = model.encoder(src_token_ids, src_mask)\n",
    "        for idx in range(1, limit_token_length): \n",
    "            trg_mask = model.make_trg_mask(trg_token_ids)\n",
    "            # print(trg_mask)\n",
    "            # print(f'trg_token_ids: {trg_token_ids.shape}')\n",
    "            next_token_tensor = model.decoder(trg_token_ids, enc_src, trg_mask, src_mask)[0, -1, :]\n",
    "            # print(f'next_token_tensor shape: {next_token_tensor.shape}')\n",
    "            next_token_id = tensor2tokenid(next_token_tensor)\n",
    "            # print(f'next_token_id: {next_token_id}')\n",
    "    \n",
    "            # append it to the trg \n",
    "            # print(f'trg_token_ids shape: {trg_token_ids.shape}')\n",
    "            # print(f'next_token_id.reshape(1, -1) shape: {next_token_id.reshape(1, -1).shape}')\n",
    "            trg_token_ids = torch.cat([trg_token_ids, next_token_id.reshape(1, -1)], dim=1)\n",
    "            \n",
    "            # break if next_token_id is end token \n",
    "            if next_token_id == trg_eos_token: \n",
    "                break\n",
    "    \n",
    "        # convert trg into string \n",
    "        print(f'{trg_token_ids.reshape(-1)}')\n",
    "        return en_tokenizer.decode(trg_token_ids.reshape(-1), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f84cfe8-1603-4914-9709-4db88e519364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,    16,    12,   107,     9,   639,  6229,    10,     9,  2253,\n",
      "         5419, 23269,  3539,   101,     3,     8,     9,  3184,     6,     4,\n",
      "            9,  4952,  4747,     2,     0], device='mps:0')\n",
      "</s> I'm always atmosphere, and one of the person.</s>\n"
     ]
    }
   ],
   "source": [
    "translated_sentence = inference(\"안녕하세요, 제 이름은 최진호입니다.\")\n",
    "print(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79680c13-d995-4125-89c9-f5811a80f84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
