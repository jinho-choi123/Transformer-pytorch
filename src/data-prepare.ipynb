{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6559c86d-1cc2-42e6-9660-fa79c2401a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@Configuration START@@\n",
      "batch_size: 128\n",
      "d_model: 256\n",
      "n_head: 2\n",
      "max_len: 128\n",
      "ffn_hidden: 64\n",
      "n_layers: 6\n",
      "drop_prob: 0.1\n",
      "epochs: 300\n",
      "init_lr: 0.001\n",
      "weight_decay: 0.0005\n",
      "clip: 1\n",
      "Using MPS as device\n",
      "project_dir: /Users/ball/Documents/workspace/transformer-tutorial\n",
      "rawdata_dir: /Users/ball/Documents/workspace/transformer-tutorial/data\n",
      "data_dir: /Users/ball/Documents/workspace/transformer-tutorial/preprocessed\n",
      "@@Configuration END@@\n"
     ]
    }
   ],
   "source": [
    "# Run the configuration \n",
    "%run ../config/config.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e2fd05-bbd7-4c10-a763-ce7e53b02200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7755997e-1d7b-4d3f-bd67-8010b15c7d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files in /Users/ball/Documents/workspace/transformer-tutorial/data/: ['9.xlsx', '5.xlsx', '4.xlsx', '8.xlsx', '3.xlsx', '2.xlsx', '1.xlsx', '10.xlsx', '7.xlsx', '6.xlsx']\n"
     ]
    }
   ],
   "source": [
    "data_files = os.listdir(rawdata_dir)\n",
    "data_files = [f for f in data_files if f[-4:] == 'xlsx']\n",
    "print(f'files in {rawdata_dir}/: {data_files}')\n",
    "\n",
    "if len(data_files) == 0:\n",
    "    print(f'ERROR!!! There are no available datas in data directory. Please follow README.md direction to prepare data!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b522cbbe-c028-4f3c-b348-58e89158b128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall data size: (1602418, 2)\n"
     ]
    }
   ],
   "source": [
    "datas = []\n",
    "\n",
    "# iter all xlsx files in data/ directory, and append korean sentence and english sentence to df_data \n",
    "for f in data_files: \n",
    "    # using calamine engine will boost the speed\n",
    "    # using default driver is extremely slow!\n",
    "    data = pd.read_excel(os.path.join(rawdata_dir, f), engine=\"calamine\")\n",
    "    data.rename(columns={'원문': \"korean\", '번역문': \"english\"}, inplace=True)\n",
    "    extracted_data = data[[\"korean\", \"english\"]]\n",
    "    datas.append(extracted_data)\n",
    "\n",
    "df_data = pd.concat(datas, ignore_index=True)\n",
    "    \n",
    "print(f'overall data size: {df_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef89d7d-9631-4ff6-8252-1ed284bd922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 320483\n",
      "test data size: 64097\n",
      "validation data size: 1217838\n"
     ]
    }
   ],
   "source": [
    "# split df_data into train test dataframe \n",
    "train_df_data, test_df_data = train_test_split(df_data, test_size=0.8, shuffle=True, random_state=123)\n",
    "valid_df_data, test_df_data = train_test_split(test_df_data, test_size=0.05, shuffle=True, random_state=123)\n",
    "print(f'train data size: {len(train_df_data)}')\n",
    "print(f'test data size: {len(test_df_data)}')\n",
    "print(f'validation data size: {len(valid_df_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa99a86-9c09-4c63-8316-2e7617a98ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test.parquet, test.parquet, validation.parquet to /Users/ball/Documents/workspace/transformer-tutorial/preprocessed/\n"
     ]
    }
   ],
   "source": [
    "train_df_data.to_parquet(path=data_dir.joinpath(\"train.parquet\"))\n",
    "test_df_data.to_parquet(path=data_dir.joinpath(\"test.parquet\"))\n",
    "valid_df_data.to_parquet(path=data_dir.joinpath(\"validation.parquet\"))\n",
    "\n",
    "print(f'Saved test.parquet, test.parquet, validation.parquet to {data_dir}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fcb32f-433a-429e-98bd-c7301fe1c58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
