{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41fd3d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:30.046508Z",
     "iopub.status.busy": "2024-11-17T20:45:30.045800Z",
     "iopub.status.idle": "2024-11-17T20:45:33.762121Z",
     "shell.execute_reply": "2024-11-17T20:45:33.761324Z",
     "shell.execute_reply.started": "2024-11-17T20:45:30.046457Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd \n",
    "import os \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd05dfa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:33.763757Z",
     "iopub.status.busy": "2024-11-17T20:45:33.763307Z",
     "iopub.status.idle": "2024-11-17T20:45:33.803128Z",
     "shell.execute_reply": "2024-11-17T20:45:33.802157Z",
     "shell.execute_reply.started": "2024-11-17T20:45:33.763724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA as device\n"
     ]
    }
   ],
   "source": [
    "# define device \n",
    "# configuration \n",
    "\n",
    "TOKENIZERS_PARALLELISM = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA as device\")\n",
    "else:\n",
    "    # Check that MPS is available\n",
    "    if not torch.backends.mps.is_available():\n",
    "        if not torch.backends.mps.is_built():\n",
    "            print(\"MPS not available because the current PyTorch install was not \"\n",
    "                  \"built with MPS enabled.\")\n",
    "        else:\n",
    "            print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                  \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU as device\")\n",
    "    else:\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS as device\")\n",
    "    \n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286843ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:33.804655Z",
     "iopub.status.busy": "2024-11-17T20:45:33.804346Z",
     "iopub.status.idle": "2024-11-17T20:45:33.811881Z",
     "shell.execute_reply": "2024-11-17T20:45:33.810775Z",
     "shell.execute_reply.started": "2024-11-17T20:45:33.804624Z"
    }
   },
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "preprocessed_directory = preprocessed_directory = os.path.join(current_path, \"preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6286b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:33.815856Z",
     "iopub.status.busy": "2024-11-17T20:45:33.815487Z",
     "iopub.status.idle": "2024-11-17T20:45:34.176282Z",
     "shell.execute_reply": "2024-11-17T20:45:34.175313Z",
     "shell.execute_reply.started": "2024-11-17T20:45:33.815824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import tokenizers\n",
    "kr_tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
    "en_tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395afba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:34.177702Z",
     "iopub.status.busy": "2024-11-17T20:45:34.177404Z",
     "iopub.status.idle": "2024-11-17T20:45:34.184263Z",
     "shell.execute_reply": "2024-11-17T20:45:34.183266Z",
     "shell.execute_reply.started": "2024-11-17T20:45:34.177671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test tokenizers \n",
    "tmp_kr_sentence = \"오늘 하교길에 길고양이를 보았는데, 너무 귀여워서 집에 데려가고 싶었다. 하지만 그러지는 않았다.\"\n",
    "tmp_en_sentence = \"The cat I saw during heading home today was so cute, that I wanted to bring it to home.\"\n",
    "\n",
    "tmp_kr_tokenized = kr_tokenizer(tmp_kr_sentence, add_special_tokens=True, padding=\"max_length\", max_length=256, truncation=True)\n",
    "tmp_en_tokenized = en_tokenizer(tmp_en_sentence, add_special_tokens=True, padding=\"max_length\", max_length=256, truncation=True)\n",
    "\n",
    "# print(kr_tokenizer.convert_ids_to_tokens(tmp_kr_tokenized.input_ids))\n",
    "# print(en_tokenizer.convert_ids_to_tokens(tmp_en_tokenized.input_ids))\n",
    "\n",
    "# print(kr_tokenizer.decode(tmp_kr_tokenized.input_ids, skip_special_tokens=True))\n",
    "\n",
    "# check if both tokenizer has pad token \n",
    "# print(kr_tokenizer.pad_token)\n",
    "# print(en_tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b24371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:34.185889Z",
     "iopub.status.busy": "2024-11-17T20:45:34.185595Z",
     "iopub.status.idle": "2024-11-17T20:45:38.072900Z",
     "shell.execute_reply": "2024-11-17T20:45:38.072072Z",
     "shell.execute_reply.started": "2024-11-17T20:45:34.185858Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(path=\"/kaggle/input/en2kr-translation/train.parquet\")\n",
    "df_test = pd.read_parquet(path=\"/kaggle/input/en2kr-translation/test.parquet\")\n",
    "df_validation = pd.read_parquet(path=\"/kaggle/input/en2kr-translation/validation.parquet\")\n",
    "\n",
    "\n",
    "\n",
    "class en2kr_Train_Dataset(Dataset): \n",
    "    def __init__(self, max_len): \n",
    "        self.data = df_train\n",
    "        self.max_len = max_len \n",
    "        self.kr_tokenizer = kr_tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.data) \n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        row = self.data.iloc[[idx]]\n",
    "        en_sentence = row[\"english\"].item()\n",
    "        kr_sentence = row[\"korean\"].item()\n",
    "        kr_tokenized_ids = self.kr_tokenizer(kr_sentence, add_special_tokens=True, padding=\"max_length\", max_length=self.max_len, truncation=True).input_ids\n",
    "        en_tokenized_ids = self.en_tokenizer(en_sentence, add_special_tokens=True, padding=\"max_length\", max_length=self.max_len, truncation=True).input_ids\n",
    "\n",
    "        # kr_tokenized = self.kr_tokenizer.convert_ids_to_tokens(kr_tokenized_ids)\n",
    "        # en_tokenized = self.en_tokenizer.convert_ids_to_tokens(en_tokenized_ids)\n",
    "\n",
    "        kr_tokenized_ids = torch.IntTensor(kr_tokenized_ids)\n",
    "        en_tokenized_ids = torch.IntTensor(en_tokenized_ids)\n",
    "        return kr_tokenized_ids, en_tokenized_ids\n",
    "        \n",
    "class en2kr_Test_Dataset(Dataset): \n",
    "    def __init__(self, max_len): \n",
    "        self.data = df_test\n",
    "        self.max_len = max_len \n",
    "        self.kr_tokenizer = kr_tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.data) \n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        row = self.data.iloc[[idx]]\n",
    "        en_sentence = row[\"english\"].item()\n",
    "        kr_sentence = row[\"korean\"].item()\n",
    "        kr_tokenized_ids = self.kr_tokenizer(kr_sentence, add_special_tokens=True, padding=\"max_length\", max_length=self.max_len, truncation=True).input_ids\n",
    "        en_tokenized_ids = self.en_tokenizer(en_sentence, add_special_tokens=True, padding=\"max_length\", max_length=self.max_len, truncation=True).input_ids\n",
    "\n",
    "        # kr_tokenized = self.kr_tokenizer.convert_ids_to_tokens(kr_tokenized_ids)\n",
    "        # en_tokenized = self.en_tokenizer.convert_ids_to_tokens(en_tokenized_ids)\n",
    "        \n",
    "        kr_tokenized_ids = torch.IntTensor(kr_tokenized_ids)\n",
    "        en_tokenized_ids = torch.IntTensor(en_tokenized_ids)\n",
    "        \n",
    "        return kr_tokenized_ids, en_tokenized_ids\n",
    "\n",
    "class en2kr_Validation_Dataset(Dataset): \n",
    "    def __init__(self, max_len): \n",
    "        self.data = df_validation\n",
    "        self.max_len = max_len \n",
    "        self.kr_tokenizer = kr_tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.data) \n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        row = self.data.iloc[[idx]]\n",
    "        en_sentence = row[\"english\"].item()\n",
    "        kr_sentence = row[\"korean\"].item()\n",
    "        kr_tokenized_ids = self.kr_tokenizer(kr_sentence, add_special_tokens=True, padding=\"max_length\", max_length=self.max_len, truncation=True).input_ids\n",
    "        en_tokenized_ids = self.en_tokenizer(en_sentence, add_special_tokens=True, padding=\"max_length\", max_length=self.max_len, truncation=True).input_ids\n",
    "\n",
    "        # kr_tokenized = self.kr_tokenizer.convert_ids_to_tokens(kr_tokenized_ids)\n",
    "        # en_tokenized = self.en_tokenizer.convert_ids_to_tokens(en_tokenized_ids)\n",
    "        \n",
    "        kr_tokenized_ids = torch.IntTensor(kr_tokenized_ids)\n",
    "        en_tokenized_ids = torch.IntTensor(en_tokenized_ids)\n",
    "        \n",
    "        return kr_tokenized_ids, en_tokenized_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8c9bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:38.074374Z",
     "iopub.status.busy": "2024-11-17T20:45:38.074027Z",
     "iopub.status.idle": "2024-11-17T20:45:38.080678Z",
     "shell.execute_reply": "2024-11-17T20:45:38.079640Z",
     "shell.execute_reply.started": "2024-11-17T20:45:38.074340Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataset = en2kr_Train_Dataset(max_len=128)\n",
    "test_dataset = en2kr_Test_Dataset(max_len=128)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,drop_last=True,  shuffle=True, generator=torch.Generator(device=device))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True, generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b8569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd6ff5e",
   "metadata": {},
   "source": [
    "# Transformer Model Implementation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c239c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:38.082053Z",
     "iopub.status.busy": "2024-11-17T20:45:38.081768Z",
     "iopub.status.idle": "2024-11-17T20:45:39.714325Z",
     "shell.execute_reply": "2024-11-17T20:45:39.713307Z",
     "shell.execute_reply.started": "2024-11-17T20:45:38.082023Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import copy \n",
    "import math \n",
    "from torch.nn.functional import log_softmax\n",
    "import pandas as pd \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "558a8a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.716553Z",
     "iopub.status.busy": "2024-11-17T20:45:39.715773Z",
     "iopub.status.idle": "2024-11-17T20:45:39.730211Z",
     "shell.execute_reply": "2024-11-17T20:45:39.729202Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.716499Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a Token Embedding \n",
    "class TokenEmbeddings(nn.Embedding): \n",
    "    \"\"\"\n",
    "    Converting token into embedding vector\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        \"\"\"\n",
    "        class for token embedding without positional encoding\n",
    "\n",
    "        :param vocab_size: number of vocabs that TokenEmbeddings can handle\n",
    "        :param d_model: dimension of embedding vector\n",
    "        \"\"\"\n",
    "        super(TokenEmbeddings, self).__init__(vocab_size, d_model, padding_idx=1)\n",
    "\n",
    "# Define Positional Encoding \n",
    "class PositionalEncoding(nn.Module): \n",
    "    \"\"\" \n",
    "    compute reusable sinusoid positional encoding\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len, device): \n",
    "        \"\"\"\n",
    "        construct sinusoid positional encoding that is going to be reused everytime when it is needed\n",
    "\n",
    "        :param d_model: dimension of embedding vector\n",
    "        :param max_len: maximum sequence length of token(a.k.a window size of attention method)\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # define a max_len * d_model size encoding matrix\n",
    "        self.encoding = torch.zeros(max_len, d_model, device=device)\n",
    "\n",
    "        # since positional encoding is not learnable, we turn off the gradient engine\n",
    "        self.encoding.requires_grad = False\n",
    "\n",
    "        # define a position at the sequence\n",
    "        pos = torch.arange(0, max_len, device=device)\n",
    "        # expand the max_len vector to max_len * 1 matrix \n",
    "        pos = pos.float().unsqueeze(dim=1)\n",
    "\n",
    "        _2i = torch.arange(0, d_model, step=2, device=device).float()\n",
    "\n",
    "        # define a sinusoid positional encoding\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "\n",
    "    def forward(self, x): \n",
    "        batch_size, seq_len = x.shape\n",
    "\n",
    "        return self.encoding[:seq_len, :]\n",
    "\n",
    "# Define Transformer Embedding \n",
    "class TransformerEmbedding(nn.Module): \n",
    "    \"\"\"\n",
    "    token embedding + positional encoding\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_len, drop_prob, device): \n",
    "        \"\"\"\n",
    "        initialize the embedding class for word+position embedding\n",
    "\n",
    "        :param vocab_size: number of vocabs that TokenEmbeddings can handle\n",
    "        :param d_model: dimension of embedding vector\n",
    "        :param max_len: maximum sequence length of token(a.k.a window size of attention method)\n",
    "        :param drop_prob: dropout probability to reduce overfitting\n",
    "        \"\"\"\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "        self.token_emb = TokenEmbeddings(vocab_size, d_model)\n",
    "        self.position_emb = PositionalEncoding(d_model, max_len, device)\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x): \n",
    "        tok_emb = self.token_emb(x)\n",
    "        pos_emb = self.position_emb(x)\n",
    "\n",
    "        return self.dropout(tok_emb+pos_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141ce087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.732005Z",
     "iopub.status.busy": "2024-11-17T20:45:39.731728Z",
     "iopub.status.idle": "2024-11-17T20:45:39.747830Z",
     "shell.execute_reply": "2024-11-17T20:45:39.746860Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.731975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Attention Block \n",
    "class AttentionBlock(nn.Module): \n",
    "    \"\"\"\n",
    "    compute scale dot product attention for Query, Key, Value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None, eps=1e-12): \n",
    "        batch_size, head, length, d_tensor = k.shape\n",
    "\n",
    "        # calculate the k_T\n",
    "        k_T = k.transpose(2, 3)\n",
    "\n",
    "        # calculate the attention weight \n",
    "        att_weight = (q @ k_T) / math.sqrt(d_tensor)\n",
    "\n",
    "        # if there are any masks that needs to be applied\n",
    "        if mask is not None:\n",
    "            att_weight = att_weight.masked_fill(mask == 0, -10000)\n",
    "\n",
    "        # calculate the softmax \n",
    "        # att_weight shape: batch_size, head, seq_len, seq_len\n",
    "        att_weight = self.softmax(att_weight)\n",
    "\n",
    "        # att_weight @ v shape: batch_size, head, seq_len, d_model\n",
    "        return att_weight @ v, att_weight\n",
    "\n",
    "# Define MultiHeadAttention Block \n",
    "class MultiHeadAttentionBlock(nn.Module): \n",
    "    \"\"\"\n",
    "    define multi head attention block using AttentionBlock module\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_head): \n",
    "        \"\"\"\n",
    "        Multi-head self-attention utilize the parallelism of GPU\n",
    "\n",
    "        :param d_model: dimension of embedding vector\n",
    "        :param n_head: number of heads\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttentionBlock, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.attention = AttentionBlock()\n",
    "        self.Wq = nn.Linear(d_model, d_model)\n",
    "        self.Wk = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # in the paper, d_v = d_k = d_q\n",
    "        self.Wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.Wconcat = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split(self, tensor): \n",
    "        \"\"\"\n",
    "        split the tensor by number of head \n",
    "\n",
    "        :param tensor: tensor of shape batch_size  * seq_len * d_model\n",
    "        :return: return tensor of shape batch_size * n_head * seq_len * d_tensor\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = tensor.shape \n",
    "\n",
    "        d_tensor = d_model // self.n_head\n",
    "\n",
    "        tensor = tensor.view(batch_size, seq_len, self.n_head, d_tensor).transpose(1, 2)\n",
    "\n",
    "        return tensor \n",
    "\n",
    "    def concat(self, tensor): \n",
    "        \"\"\"\n",
    "        concat tensor. Inverse operation of split\n",
    "\n",
    "        :param tensor: tensor of shape batch_size * n_head * seq_len * d_tensor \n",
    "        :return: return tensor of shape batch_size * seq_len * d_model\n",
    "        \"\"\"\n",
    "        batch_size, n_head, seq_len, d_tensor = tensor.shape\n",
    "\n",
    "        d_model = n_head * d_tensor\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
    "        return tensor \n",
    "    \n",
    "\n",
    "    def forward(self, q, k, v, mask=None): \n",
    "        # apply linear transformation to derive q, k, v \n",
    "        q, k, v = self.Wq(q), self.Wk(k), self.Wv(v)\n",
    "\n",
    "        # split the tensor by number of heads\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "\n",
    "        # apply attention to q, k, v \n",
    "        out, att_weight = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        # concat \n",
    "        out = self.concat(out)\n",
    "\n",
    "        # apply concat weight \n",
    "        out = self.Wconcat(out)\n",
    "        return out \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703f4ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.749401Z",
     "iopub.status.busy": "2024-11-17T20:45:39.749054Z",
     "iopub.status.idle": "2024-11-17T20:45:39.760501Z",
     "shell.execute_reply": "2024-11-17T20:45:39.759652Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.749369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define LayerNorm \n",
    "class LayerNorm(nn.Module): \n",
    "    \"\"\"\n",
    "    Normalize all features for each samples. \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, eps=1e-12): \n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps \n",
    "\n",
    "    def forward(self, x): \n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True, unbiased=False)\n",
    "\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3feefb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.761898Z",
     "iopub.status.busy": "2024-11-17T20:45:39.761618Z",
     "iopub.status.idle": "2024-11-17T20:45:39.769634Z",
     "shell.execute_reply": "2024-11-17T20:45:39.768814Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.761867Z"
    }
   },
   "outputs": [],
   "source": [
    "# define FeedForward Network \n",
    "class FeedForwardBlock(nn.Module): \n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1): \n",
    "        super(FeedForwardBlock, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden) \n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU() \n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.linear1(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x) \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f3bcc95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.773621Z",
     "iopub.status.busy": "2024-11-17T20:45:39.773319Z",
     "iopub.status.idle": "2024-11-17T20:45:39.787320Z",
     "shell.execute_reply": "2024-11-17T20:45:39.786495Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.773591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Encoder Layer \n",
    "class EncoderLayer(nn.Module): \n",
    "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob): \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttentionBlock(d_model, n_head)\n",
    "        self.norm1 = LayerNorm(d_model) \n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.ffn = FeedForwardBlock(d_model, ffn_hidden, drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, x, src_mask): \n",
    "        residual = x \n",
    "        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n",
    "\n",
    "        x = self.dropout1(x) \n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        residual = x \n",
    "        x = self.ffn(x) \n",
    "\n",
    "        x =  self.dropout2(x)\n",
    "        x = self.norm2(x + residual)\n",
    "\n",
    "        return x \n",
    "\n",
    "# Define Decoder Layer \n",
    "class DecoderLayer(nn.Module): \n",
    "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob): \n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttentionBlock(d_model, n_head)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.enc_dec_attention = MultiHeadAttentionBlock(d_model, n_head)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.ffn = FeedForwardBlock(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, dec, enc, trg_mask, src_mask): \n",
    "        residual = dec\n",
    "        x = self.self_attention(q=dec, k=dec, v=dec, mask=trg_mask)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        if enc is not None: \n",
    "            residual = x \n",
    "            x = self.enc_dec_attention(q=x, k=enc, v=enc, mask=src_mask)\n",
    "            x = self.dropout2(x) \n",
    "            x = self.norm2(x + residual)\n",
    "\n",
    "        residual = x \n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.norm3(x + residual)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6eaf026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.788941Z",
     "iopub.status.busy": "2024-11-17T20:45:39.788634Z",
     "iopub.status.idle": "2024-11-17T20:45:39.807284Z",
     "shell.execute_reply": "2024-11-17T20:45:39.806301Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.788906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Encoder Model\n",
    "class Encoder(nn.Module): \n",
    "    \"\"\"\n",
    "    Encoder for Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device): \n",
    "        super(Encoder, self).__init__()\n",
    "        self.emb = TransformerEmbedding(d_model=d_model, max_len=max_len, vocab_size=enc_voc_size, drop_prob=drop_prob, device=device)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model, ffn_hidden=ffn_hidden, n_head=n_head, drop_prob=drop_prob) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, src_mask): \n",
    "        x = self.emb(x) \n",
    "        for layer in self.layers: \n",
    "            x = layer(x, src_mask)\n",
    "\n",
    "        return x\n",
    "\n",
    "        \n",
    "class Decoder(nn.Module): \n",
    "    \"\"\"\n",
    "    Decoder for Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device): \n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = TransformerEmbedding(d_model=d_model, max_len=max_len, vocab_size=dec_voc_size, drop_prob=drop_prob, device=device)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model, ffn_hidden=ffn_hidden, n_head=n_head, drop_prob=drop_prob) for _ in range(n_layers)])\n",
    "\n",
    "        self.linear = nn.Linear(d_model, dec_voc_size)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask): \n",
    "        trg = self.emb(trg)\n",
    "        for layer in self.layers: \n",
    "            trg = layer(trg, enc_src, trg_mask, src_mask) \n",
    "\n",
    "        output = self.linear(trg)\n",
    "        return output\n",
    "    \n",
    "\n",
    "# Define Transformer Model \n",
    "class Transformer(nn.Module): \n",
    "    \"\"\"\n",
    "    Transformer Model\n",
    "    \"\"\"\n",
    "    def __init__(self, src_pad_token, trg_pad_token, trg_sos_token, enc_voc_size, dec_voc_size, n_head, max_len, ffn_hidden, n_layers, drop_prob, device): \n",
    "        \"\"\"\n",
    "        Constructing Transformer Model \n",
    "\n",
    "        :param src_pad_token: embedding vector that represents <pad> in source \n",
    "        :param trg_pad_token: embedding vector that represents <pad> in target \n",
    "        :param trg_sos_token: embedding vector that represents <sos> in target \n",
    "        :params enc_voc_size: number of vocabs that encoderEmbedder can handle\n",
    "        :params dec_voc_size: number of vocabs that decoderEmbedder can handle\n",
    "        :params ffn_hidden: hidden vector dimension for fastfeedforward layer \n",
    "        :params n_layers: number of EncoderLayer/DecoderLayer used\n",
    "        :params drop_prob: dropout probability\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.src_pad_token = src_pad_token\n",
    "        self.trg_pad_token = trg_pad_token\n",
    "        self.trg_sos_token = trg_sos_token\n",
    "        self.device = device\n",
    "        self.n_head = n_head\n",
    "        self.encoder = Encoder(d_model=d_model, n_head=n_head, max_len=max_len, ffn_hidden=ffn_hidden, enc_voc_size=enc_voc_size, drop_prob=drop_prob, n_layers=n_layers, device=device)\n",
    "        self.decoder = Decoder(d_model=d_model, n_head=n_head, max_len=max_len, ffn_hidden=ffn_hidden, dec_voc_size=dec_voc_size, drop_prob=drop_prob, n_layers=n_layers, device=device)\n",
    "\n",
    "    def make_src_mask(self, src): \n",
    "        # print(f'src: {src}')\n",
    "        # print(f'src_pad_token: {self.src_pad_token}')\n",
    "        # print(f'src != self.src_pad_token: {src != self.src_pad_token}')\n",
    "        src_mask = (src != self.src_pad_token).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg): \n",
    "        trg_pad_mask = (trg != self.trg_pad_token).unsqueeze(1).unsqueeze(3)\n",
    "        trg_len = trg.shape[1]\n",
    "\n",
    "        # make a look-ahead mask using torch.tril \n",
    "        # [[1 0 0]\n",
    "        #  [1 1 0]\n",
    "        #  [1 1 1]]\n",
    "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n",
    "\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask\n",
    "        \n",
    "    \n",
    "    def forward(self, src, trg): \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b784e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a95c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3f931d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.809137Z",
     "iopub.status.busy": "2024-11-17T20:45:39.808784Z",
     "iopub.status.idle": "2024-11-17T20:45:39.821059Z",
     "shell.execute_reply": "2024-11-17T20:45:39.820294Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.809097Z"
    }
   },
   "outputs": [],
   "source": [
    "import math \n",
    "from collections import Counter \n",
    "import numpy \n",
    "\n",
    "# compute the statistics for BLEU \n",
    "def bleu_stats(hypothesis, reference): \n",
    "    stats = [] \n",
    "    stats.append(len(hypothesis))\n",
    "    stats.append(len(reference))\n",
    "\n",
    "    for n in range(1, 5): \n",
    "        s_ngrams = Counter(\n",
    "            [tuple(hypothesis[i:i+n]) for i in range(len(hypothesis) + 1 - n)]\n",
    "        )\n",
    "\n",
    "        r_ngrams = Counter(\n",
    "            [tuple(reference[i:i+n]) for i in range(len(reference) + 1 - n)]\n",
    "        )\n",
    "\n",
    "        stats.append(max([sum((s_ngrams & r_ngrams).values()), 0]))\n",
    "        stats.append(max([len(hypothesis) + 1 - n, 0]))\n",
    "\n",
    "    return stats \n",
    "\n",
    "def bleu(stats): \n",
    "    for i in stats:\n",
    "        if i == 0:\n",
    "            return 0 \n",
    "\n",
    "    (h_len, r_len) = stats[:2]\n",
    "    log_bleu_prec = sum(\n",
    "        [math.log(float(x)/y) for x, y in zip(stats[2::2], stats[3::2])]\n",
    "    ) / 4.\n",
    "\n",
    "    return math.exp(min([0, 1 - float(r_len) / h_len]) + log_bleu_prec)\n",
    "\n",
    "def get_bleu(hypotheses, reference):\n",
    "    \"\"\"Get validation BLEU score for dev set.\"\"\"\n",
    "    stats = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    for hyp, ref in zip(hypotheses, reference):\n",
    "        stats += np.array(bleu_stats(hyp, ref))\n",
    "    return 100 * bleu(stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c9ae8",
   "metadata": {},
   "source": [
    "# Train the Model using datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b5e682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.822734Z",
     "iopub.status.busy": "2024-11-17T20:45:39.822285Z",
     "iopub.status.idle": "2024-11-17T20:45:39.834556Z",
     "shell.execute_reply": "2024-11-17T20:45:39.833750Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.822691Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from datetime import datetime\n",
    "import torch \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c18edda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.836579Z",
     "iopub.status.busy": "2024-11-17T20:45:39.835838Z",
     "iopub.status.idle": "2024-11-17T20:45:39.846098Z",
     "shell.execute_reply": "2024-11-17T20:45:39.845281Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.836543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA as device\n"
     ]
    }
   ],
   "source": [
    "# define device \n",
    "# configuration \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA as device\")\n",
    "else:\n",
    "    # Check that MPS is available\n",
    "    if not torch.backends.mps.is_available():\n",
    "        if not torch.backends.mps.is_built():\n",
    "            print(\"MPS not available because the current PyTorch install was not \"\n",
    "                  \"built with MPS enabled.\")\n",
    "        else:\n",
    "            print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                  \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU as device\")\n",
    "    else:\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS as device\")\n",
    "    \n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0f2cf98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.848263Z",
     "iopub.status.busy": "2024-11-17T20:45:39.847492Z",
     "iopub.status.idle": "2024-11-17T20:45:39.857282Z",
     "shell.execute_reply": "2024-11-17T20:45:39.856396Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.848185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define some configuration of training \n",
    "d_model = 256 \n",
    "n_head = 8\n",
    "max_len = 128\n",
    "ffn_hidden = 128 \n",
    "n_layers=6\n",
    "drop_prob=0.1\n",
    "epochs=300\n",
    "init_lr = 1e-3\n",
    "weight_decay = 5e-4\n",
    "clip = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df35bf91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.858778Z",
     "iopub.status.busy": "2024-11-17T20:45:39.858466Z",
     "iopub.status.idle": "2024-11-17T20:45:39.867173Z",
     "shell.execute_reply": "2024-11-17T20:45:39.866286Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.858746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_pad_token: 0\n",
      "trg_pad_token: 0\n",
      "trg_sos_token: 102\n",
      "enc_voc_size: 42000\n",
      "dec_voc_size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Define some configuration of training \n",
    "\n",
    "src_pad_token = kr_tokenizer.pad_token_id\n",
    "trg_pad_token = en_tokenizer.pad_token_id\n",
    "trg_sos_token = en_tokenizer.sep_token_id\n",
    "enc_voc_size = kr_tokenizer.vocab_size\n",
    "dec_voc_size = en_tokenizer.vocab_size\n",
    "\n",
    "print(f'src_pad_token: {src_pad_token}')\n",
    "print(f'trg_pad_token: {trg_pad_token}')\n",
    "print(f'trg_sos_token: {trg_sos_token}')\n",
    "print(f'enc_voc_size: {enc_voc_size}')\n",
    "print(f'dec_voc_size: {dec_voc_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f01d69b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:39.868443Z",
     "iopub.status.busy": "2024-11-17T20:45:39.868128Z",
     "iopub.status.idle": "2024-11-17T20:45:40.071597Z",
     "shell.execute_reply": "2024-11-17T20:45:40.070567Z",
     "shell.execute_reply.started": "2024-11-17T20:45:39.868412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameter #: 31953210\n"
     ]
    }
   ],
   "source": [
    "# Prepare the model \n",
    "model = Transformer(src_pad_token, trg_pad_token, trg_sos_token, enc_voc_size, dec_voc_size,n_head, max_len, ffn_hidden, n_layers, drop_prob, device).to(device)\n",
    "model.train()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'model parameter #: {count_parameters(model)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba4bbc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:40.073649Z",
     "iopub.status.busy": "2024-11-17T20:45:40.073212Z",
     "iopub.status.idle": "2024-11-17T20:45:40.080596Z",
     "shell.execute_reply": "2024-11-17T20:45:40.079593Z",
     "shell.execute_reply.started": "2024-11-17T20:45:40.073601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup optimizer \n",
    "optimizer = Adam(params=model.parameters(), lr=init_lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=src_pad_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a40ea62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:40.082735Z",
     "iopub.status.busy": "2024-11-17T20:45:40.082341Z",
     "iopub.status.idle": "2024-11-17T20:45:40.094885Z",
     "shell.execute_reply": "2024-11-17T20:45:40.093915Z",
     "shell.execute_reply.started": "2024-11-17T20:45:40.082690Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch_num): \n",
    "    train_epoch_loss = 0 \n",
    "\n",
    "    for step, (kr_tokenized, en_tokenized) in tqdm(enumerate(train_dataloader)): \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        kr_tokenized = kr_tokenized.to(device)\n",
    "        en_tokenized = en_tokenized.to(device)\n",
    "\n",
    "        out = model(kr_tokenized, en_tokenized[:, :-1])\n",
    "\n",
    "        # remove sos token from en_tokenized when calculating loss because out will not include sos token. \n",
    "        en_tokenized = en_tokenized[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        out = out.contiguous().view(-1, out.shape[-1])\n",
    "\n",
    "        loss = loss_func(out.to(device), en_tokenized.type(torch.LongTensor).to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f'EPOCH #{epoch_num} STEP #{step} | loss: {loss.item()}, avg_loss: {train_epoch_loss / (step + 1)}')\n",
    "\n",
    "    train_step_loss = train_epoch_loss / (step+1)\n",
    "    # After training epoch, do evaluation \n",
    "\n",
    "    return train_step_loss\n",
    "    \n",
    "\n",
    "# evaluate the model \n",
    "def evaluate(): \n",
    "    model.eval()\n",
    "    test_epoch_loss = 0 \n",
    "    test_bleu_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for step, (kr_tokenized, en_tokenized) in tqdm(enumerate(test_dataloader)): \n",
    "            kr_tokenized = kr_tokenized.to(device)\n",
    "            en_tokenized = en_tokenized.to(device)\n",
    "\n",
    "            out = model(kr_tokenized, en_tokenized[:, :-1])\n",
    "\n",
    "            # remove sos token from en_tokenized when calculating loss because out will not include sos token. \n",
    "            en_tokenized = en_tokenized[:, 1:].contiguous().view(-1)\n",
    "    \n",
    "            out = out.contiguous().view(-1, out.shape[-1])\n",
    "            loss = loss_func(out.to(device), en_tokenized.type(torch.LongTensor).to(device))\n",
    "            test_epoch_loss += loss.item()\n",
    "\n",
    "            # calcuate the bleu \n",
    "            # TODO\n",
    "    return test_step_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26eb68b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:45:40.096560Z",
     "iopub.status.busy": "2024-11-17T20:45:40.096165Z",
     "iopub.status.idle": "2024-11-17T22:06:40.633467Z",
     "shell.execute_reply": "2024-11-17T22:06:40.631684Z",
     "shell.execute_reply.started": "2024-11-17T20:45:40.096516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #0 | loss: 10.541214942932129, avg_loss: 10.541214942932129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:56,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #100 | loss: 6.313336372375488, avg_loss: 7.000858165249966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:51,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #200 | loss: 5.790494918823242, avg_loss: 6.506908468939178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [02:46,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #300 | loss: 5.443808078765869, avg_loss: 6.209476363223256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [03:41,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #400 | loss: 5.416319847106934, avg_loss: 6.0133354907618495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [04:37,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #500 | loss: 5.411207675933838, avg_loss: 5.8705325869029155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [05:32,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #600 | loss: 5.20664644241333, avg_loss: 5.762033244337695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [06:27,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #700 | loss: 5.181723117828369, avg_loss: 5.677373403149223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [07:22,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #800 | loss: 5.096766471862793, avg_loss: 5.608622318796451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [08:17,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #900 | loss: 4.993821144104004, avg_loss: 5.552498687253014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [09:12,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1000 | loss: 5.038311004638672, avg_loss: 5.504494700398478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [10:07,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1100 | loss: 4.971671104431152, avg_loss: 5.463236480924241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [11:03,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1200 | loss: 5.03561544418335, avg_loss: 5.427038662836614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [11:58,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1300 | loss: 4.888619422912598, avg_loss: 5.397040049357198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [12:54,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1400 | loss: 4.945991039276123, avg_loss: 5.370804591999149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [13:49,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1500 | loss: 5.102868556976318, avg_loss: 5.346625537732535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1601it [14:44,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1600 | loss: 5.013057708740234, avg_loss: 5.326211640717163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1701it [15:39,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1700 | loss: 5.014945030212402, avg_loss: 5.3069283759012285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801it [16:34,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1800 | loss: 5.120586395263672, avg_loss: 5.288847078157094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1901it [17:30,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #1900 | loss: 4.906405925750732, avg_loss: 5.2724330526850585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [18:25,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2000 | loss: 5.081276893615723, avg_loss: 5.257734864667199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2101it [19:21,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2100 | loss: 5.065474033355713, avg_loss: 5.2440520270219135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2201it [20:16,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2200 | loss: 5.084625720977783, avg_loss: 5.230697857147453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2301it [21:12,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2300 | loss: 4.996845722198486, avg_loss: 5.21819617322402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2401it [22:07,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2400 | loss: 4.797029495239258, avg_loss: 5.206418680876605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [23:03,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2500 | loss: 4.789111137390137, avg_loss: 5.194752705759737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2601it [23:58,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2600 | loss: 4.946078300476074, avg_loss: 5.183212106478118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2701it [24:54,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2700 | loss: 4.8410420417785645, avg_loss: 5.172599741460129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2801it [25:49,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2800 | loss: 4.975810527801514, avg_loss: 5.161925049944887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2901it [26:45,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #2900 | loss: 4.855827808380127, avg_loss: 5.152057188455502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [27:40,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3000 | loss: 4.9022369384765625, avg_loss: 5.142554531332573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3101it [28:36,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3100 | loss: 4.8263068199157715, avg_loss: 5.133201427822612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3201it [29:32,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3200 | loss: 4.748086452484131, avg_loss: 5.125047830148475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3301it [30:27,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3300 | loss: 4.929564476013184, avg_loss: 5.116490756840606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3401it [31:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3400 | loss: 4.896345138549805, avg_loss: 5.10930697913031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [32:19,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3500 | loss: 4.718604564666748, avg_loss: 5.102668470466045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3601it [33:14,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3600 | loss: 4.810760498046875, avg_loss: 5.0973838025151075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3701it [34:10,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3700 | loss: 4.950533390045166, avg_loss: 5.092490433937986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3801it [35:05,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3800 | loss: 4.846146106719971, avg_loss: 5.088402448657687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3901it [36:01,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #3900 | loss: 4.950700283050537, avg_loss: 5.085229725753366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [36:56,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4000 | loss: 4.815249443054199, avg_loss: 5.082221902152712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4101it [37:52,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4100 | loss: 5.09555721282959, avg_loss: 5.0805277411631335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4201it [38:47,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4200 | loss: 5.07959508895874, avg_loss: 5.079366654334991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4301it [39:43,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4300 | loss: 5.133204460144043, avg_loss: 5.078668712765858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4401it [40:38,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4400 | loss: 5.206789016723633, avg_loss: 5.0783725002629465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [41:33,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4500 | loss: 5.012576103210449, avg_loss: 5.078908734468851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4601it [42:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4600 | loss: 5.075676441192627, avg_loss: 5.080065226145502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4701it [43:24,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4700 | loss: 5.181363105773926, avg_loss: 5.081968600839738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4801it [44:20,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4800 | loss: 5.306509017944336, avg_loss: 5.084116335040305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4901it [45:16,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #4900 | loss: 5.222613334655762, avg_loss: 5.086588747962059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [46:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5000 | loss: 5.2342000007629395, avg_loss: 5.08989161478236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5101it [47:07,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5100 | loss: 5.229423999786377, avg_loss: 5.093037656418741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5201it [48:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5200 | loss: 5.279235363006592, avg_loss: 5.097134287415548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5301it [48:58,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5300 | loss: 5.332743167877197, avg_loss: 5.101440882597346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5401it [49:54,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5400 | loss: 5.498273849487305, avg_loss: 5.1060260777296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [50:49,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5500 | loss: 5.3998517990112305, avg_loss: 5.111038852921184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5601it [51:45,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5600 | loss: 5.4574456214904785, avg_loss: 5.116451723408304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5701it [52:41,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5700 | loss: 5.429754257202148, avg_loss: 5.12169444931116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5801it [53:37,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5800 | loss: 5.391129493713379, avg_loss: 5.1273660608826575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5901it [54:32,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #5900 | loss: 5.488823413848877, avg_loss: 5.133220429380876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [55:27,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6000 | loss: 5.512679576873779, avg_loss: 5.139298893614344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6101it [56:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6100 | loss: 5.570666313171387, avg_loss: 5.145330566868315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6201it [57:18,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6200 | loss: 5.684518337249756, avg_loss: 5.151806959162372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6301it [58:14,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6300 | loss: 5.49767541885376, avg_loss: 5.158379687333633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6401it [59:09,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6400 | loss: 5.586667537689209, avg_loss: 5.164629202599713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [1:00:05,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6500 | loss: 5.442760467529297, avg_loss: 5.170644631038866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6601it [1:01:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6600 | loss: 5.6463117599487305, avg_loss: 5.176537555774908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6701it [1:01:55,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6700 | loss: 5.514750957489014, avg_loss: 5.182439062528122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6801it [1:02:51,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6800 | loss: 5.511746406555176, avg_loss: 5.188359956709081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6901it [1:03:46,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #6900 | loss: 5.596418857574463, avg_loss: 5.19424016149886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [1:04:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7000 | loss: 5.626104354858398, avg_loss: 5.20006668422924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7101it [1:05:37,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7100 | loss: 5.8297271728515625, avg_loss: 5.206271656330766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7201it [1:06:33,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7200 | loss: 5.77896785736084, avg_loss: 5.213157742209872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7301it [1:07:28,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7300 | loss: 5.768976211547852, avg_loss: 5.219090037469324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7401it [1:08:24,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7400 | loss: 5.6462602615356445, avg_loss: 5.224401397328815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7501it [1:09:19,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7500 | loss: 5.57719612121582, avg_loss: 5.229337397423955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7601it [1:10:15,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7600 | loss: 5.598400115966797, avg_loss: 5.234182435640331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7701it [1:11:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7700 | loss: 5.62114953994751, avg_loss: 5.238769987034745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7801it [1:12:06,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7800 | loss: 5.6087727546691895, avg_loss: 5.243139215378162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7901it [1:13:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #7900 | loss: 5.602408409118652, avg_loss: 5.247336042785838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [1:13:57,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8000 | loss: 5.518220901489258, avg_loss: 5.251457450479556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8101it [1:14:52,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8100 | loss: 5.470426559448242, avg_loss: 5.255578789029971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8201it [1:15:47,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8200 | loss: 5.6926751136779785, avg_loss: 5.260010766686499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8301it [1:16:42,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8300 | loss: 5.641053199768066, avg_loss: 5.264280108626586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8401it [1:17:38,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8400 | loss: 5.5576019287109375, avg_loss: 5.268352349277565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8501it [1:18:34,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8500 | loss: 5.505454063415527, avg_loss: 5.272131330895993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8601it [1:19:29,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8600 | loss: 5.646795749664307, avg_loss: 5.275898174329797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8701it [1:20:25,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 STEP #8700 | loss: 5.575753211975098, avg_loss: 5.279477310268348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8764it [1:20:59,  1.80it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(epoch)\n\u001b[0;32m----> 5\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     best_vloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100_000_000\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Train Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 42\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(test_dataloader)): \n\u001b[0;32m---> 42\u001b[0m         kr_tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     43\u001b[0m         en_tokenized \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(kr_tokenized, en_tokenized[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(epoch)\n",
    "    test_loss = evaluate()\n",
    "\n",
    "    best_vloss = 100_000_000\n",
    "\n",
    "    print(f'Epoch {epoch}: Train Loss {train_loss}, Test Loss {test_loss}')\n",
    "\n",
    "    if test_loss < best_vloss:\n",
    "        best_vloss = avg_vloss \n",
    "        model_path = f'models/model_{timestamp}_{epoch}' \n",
    "        torch.save(model.state_dict(), model_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a87e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6107863,
     "sourceId": 9935348,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
